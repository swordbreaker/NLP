{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import math\n",
    "import itertools\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os.path\n",
    "from typing import Callable\n",
    "from nltk.corpus import brown\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method TaggedCorpusReader.sents of <TaggedCorpusReader in 'C:\\\\Users\\\\tobia\\\\Jupiter\\\\NLP\\\\Assignment2'>>\n"
     ]
    }
   ],
   "source": [
    "mycorpus = nltk.corpus.reader.TaggedCorpusReader(\"\", \"POS_German_train.txt\")\n",
    "\n",
    "print(mycorpus.sents(categories=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'I do not like green eggs and ham.'\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(categories='news', tagset='universal')\n",
    "brown_sents = brown.sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),  # gerunds\n",
    "    (r'.*ed$', 'VERB'),  # simple past\n",
    "    (r'.*es$', 'VERB'),  # 3rd singular present\n",
    "    (r'.*ould$', 'VERB'),  # modals\n",
    "    (r'and', 'CONJ'),  # and\n",
    "    (r'to', 'PRT'),  # to\n",
    "    (r'^th.*', 'DET'),  # the\n",
    "    (r'o[nf]', 'ADP'),  # of,on\n",
    "    (r'[.,;!?\\'`]', '.'),  # . and , etc.\n",
    "    (r'.*\\'s$', 'NOUN'),  # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),  # plural nouns\n",
    "    (r'^‐?[0‐9]+(.[0‐9]+)?$', 'NUM'),  # cardinal numbers\n",
    "    (r'.*ly$', 'ADV'),  # adverbs\n",
    "    (r'.*', 'NOUN')  # nouns (default)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "fd = nltk.FreqDist(brown.words(categories='news'))  # frequency distribution of words\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news', tagset='universal'))\n",
    "likely_100_tags = dict((word, cfd[word].max()) for (word, _) in fd.most_common(10000))\n",
    "\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_100_tags,  # assign 'NOUN' for OOV words\n",
    "                                     backoff=nltk.DefaultTagger('NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of Bigram  Tagger:  0.932944746856785\n",
      "     |                             C           N           P           V       |\n",
      "     |           A     A     A     O     D     O     N     R     P     E       |\n",
      "     |           D     D     D     N     E     U     U     O     R     R       |\n",
      "     |     .     J     P     V     J     T     N     M     N     T     B     X |\n",
      "-----+-------------------------------------------------------------------------+\n",
      "   . | <7099>    .     .     .     .     .     .     .     .     .     .     . |\n",
      " ADJ |     . <3548>    5   102     .     6  1117     .     .     7   173     . |\n",
      " ADP |     .     3 <6887>   51    16    11    29     .     2   598    16     . |\n",
      " ADV |     .   183   142 <2541>    6    17    74     .     .    32     2     . |\n",
      "CONJ |     .     .     2     7 <1845>    3     5     .     .     .     .     . |\n",
      " DET |     .     .    52     2     3 <7351>    6     .     2     .     .     . |\n",
      "NOUN |     2   157     3    32     .    17<14246>   23     .    20   668     2 |\n",
      " NUM |     1     .     .     .     .     .    78  <643>    .     .     .     . |\n",
      "PRON |     .     .    95     .     .    19     8     . <2169>    .     .     . |\n",
      " PRT |     .    13   134     9     .     .    17     .     . <1360>    3     . |\n",
      "VERB |     .    34    17     4     .     3   915     .     .     . <8923>    . |\n",
      "   X |     .     1     .     .     .     .    33     .     .     .     3    <7>|\n",
      "-----+-------------------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "0.9190799298746835\n",
      "     |                             C           N           P           V       |\n",
      "     |           A     A     A     O     D     O     N     R     P     E       |\n",
      "     |           D     D     D     N     E     U     U     O     R     R       |\n",
      "     |     .     J     P     V     J     T     N     M     N     T     B     X |\n",
      "-----+-------------------------------------------------------------------------+\n",
      "   . | <7095>    .     .     .     .     .     .     .     .     4     .     . |\n",
      " ADJ |     . <4122>    2    92     2     1   666     7     .     .    66     . |\n",
      " ADP |     .     9 <6849>   29    17    20    13     .     .   640    36     . |\n",
      " ADV |     .    97    70 <2667>   14    32    83     2     .     7    18     7 |\n",
      "CONJ |     .     .     .     6 <1854>    2     .     .     .     .     .     . |\n",
      " DET |     .     .    29     1     4 <6468>   16     .   898     .     .     . |\n",
      "NOUN |     3   343     6    30     1     5<14588>   25     .     .   168     1 |\n",
      " NUM |     .    30     .     .     .     .    18  <673>    .     .     1     . |\n",
      "PRON |     .     2    15     1     .    82    13     . <2178>    .     .     . |\n",
      " PRT |     .    17    61    39     1   245    51     .     1 <1102>   17     2 |\n",
      "VERB |     .   234    13    14     1     2   460     2     .     2 <9167>    1 |\n",
      "   X |     .     5     .     .     .     .    34     .     .     .     1    <4>|\n",
      "-----+-------------------------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "0.9214823712745925\n"
     ]
    }
   ],
   "source": [
    "# Splitt data set\n",
    "size = int(len(brown.words(categories='news')) * 0.8)\n",
    "\n",
    "train_set = brown.tagged_words(categories='news')[:size]\n",
    "eval_set = brown.tagged_words(categories='news')[size:]\n",
    "\n",
    "# Splitt data set\n",
    "size = int(len(brown_tagged_sents) * 0.8)\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "\n",
    "t0 = nltk.DefaultTagger('NOUN')\n",
    "t1 = nltk.RegexpTagger(patterns, backoff=t0)\n",
    "t2 = nltk.UnigramTagger(model=likely_100_tags, backoff=t1)\n",
    "t3 = nltk.UnigramTagger(train_sents, backoff=t2)\n",
    "t4 = nltk.BigramTagger(train_sents, backoff=t3)\n",
    "\n",
    "# t0 = nltk.DefaultTagger('NN')\n",
    "# t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n",
    "# t3 = nltk.UnigramTagger(model=likely_100_tags, backoff=t1)\n",
    "# t4 = nltk.BigramTagger( train_sents, backoff=t3)\n",
    "t_final = t4\n",
    "\n",
    "print(\"accuracy of Bigram  Tagger: \", t_final.evaluate(test_sents))\n",
    "# print(\"pos tag: \", nltk.pos_tag(test_sents) )\n",
    "\n",
    "\n",
    "\n",
    "test_tags = [tag for sent in brown.sents(categories='editorial') for (word, tag) in t_final.tag(sent)]\n",
    "gold_tags = [tag for (word, tag) in brown.tagged_words(categories='editorial', tagset='universal')]\n",
    "\n",
    "print(nltk.ConfusionMatrix(gold_tags, test_tags))\n",
    "print(t_final.evaluate(brown.tagged_sents(categories='editorial', tagset='universal')))\n",
    "\n",
    "pos_tag = nltk.pos_tag(brown.words(categories='editorial'), tagset='universal')\n",
    "test_tags = [tag for (word, tag) in pos_tag]\n",
    "conf_mat = nltk.ConfusionMatrix(gold_tags, test_tags)\n",
    "print(conf_mat)\n",
    "print(nltk.accuracy(gold_tags, test_tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
